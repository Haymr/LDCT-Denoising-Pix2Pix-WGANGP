# LDCT Denoising with Pix2Pix + WGAN-GP

A hybrid Pix2Pix + WGAN-GP model for Low-Dose CT image denoising.

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.10+-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## ğŸ“‹ Features

- **Hybrid Model**: Pix2Pix U-Net Generator + WGAN-GP loss
- **High Performance**: PSNR ~41.7 dB, SSIM ~0.94
- **Desktop Application**: Drag-and-drop DICOM processing
- **External Validation**: Tested on PhantomX dataset

## ğŸš€ Quick Start

### Installation

```bash
git clone https://github.com/yourusername/LDCT-Denoising-Pix2Pix-WGANGP.git
cd LDCT-Denoising-Pix2Pix-WGANGP
pip install -r requirements.txt
```

### Desktop Application

```bash
python app/main.py
```

Simply drag and drop a DICOM file, and the model will automatically denoise it.

## ğŸ“ Project Structure

```
â”œâ”€â”€ app/                          # Desktop application
â”‚   â”œâ”€â”€ main.py                   # PyQt5 GUI
â”‚   â”œâ”€â”€ preprocessing.py          # DICOM processing
â”‚   â”œâ”€â”€ model.py                  # U-Net Generator
â”‚   â””â”€â”€ comparison_widget.py      # Comparison views
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_model_architecture.ipynb    # Model definitions
â”‚   â”œâ”€â”€ 02_data_preprocessing.ipynb    # Data preprocessing
â”‚   â”œâ”€â”€ 03_training.ipynb              # Training loop
â”‚   â”œâ”€â”€ 04_validation_internal.ipynb   # PSNR/SSIM evaluation
â”‚   â””â”€â”€ 05_external_test_phantomx.ipynb# External test
â”‚
â”œâ”€â”€ G_epoch_50.h5                 # Trained model weights
â””â”€â”€ requirements.txt              # Dependencies
```

## ğŸ”¬ Model Architecture

```
Input (256x256x1)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     U-Net Generator         â”‚
â”‚  â€¢ 8-layer Encoder          â”‚
â”‚  â€¢ 7-layer Decoder          â”‚
â”‚  â€¢ Skip Connections         â”‚
â”‚  â€¢ tanh activation          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Output (256x256x1)
```

**Loss Functions:**
- Wasserstein Loss + Gradient Penalty (discriminator)
- Wasserstein Loss + L1 Reconstruction (generator)

## ğŸ“Š Results

| Dataset | PSNR (dB) | SSIM |
|---------|-----------|------|
| Mayo (Validation) | 41.73 Â± 5.84 | 0.941 Â± 0.045 |
| PhantomX (External) | - | - |

## ğŸ¯ Use Cases

- **Radiology**: Enhance low-dose CT scan quality
- **Research**: Develop LDCT denoising methods
- **Education**: Learn GAN architectures

## ğŸ“– Notebooks

Run the notebooks in order to understand the project:

1. **01_model_architecture.ipynb** - Generator and Discriminator architectures
2. **02_data_preprocessing.ipynb** - DICOM to NPY conversion
3. **03_training.ipynb** - Model training
4. **04_validation_internal.ipynb** - PSNR/SSIM calculation
5. **05_external_test_phantomx.ipynb** - Independent dataset testing

## ğŸ› ï¸ Requirements

- Python 3.9+
- TensorFlow 2.10+
- PyQt5 (for desktop app)
- CUDA-enabled GPU (recommended for training)

## ğŸ“ License

MIT License - See [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

- Mayo Clinic LDCT Dataset
- PhantomX Abdomen/Pelvis Dataset
