{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model DeÄŸerlendirmesi: PSNR ve SSIM\n",
                "\n",
                "EÄŸitilen modelin kalitesini Ã¶lÃ§mek iÃ§in iki metrik kullanÄ±yoruz:\n",
                "\n",
                "- **PSNR (Peak Signal-to-Noise Ratio)**: YÃ¼ksek deÄŸer = daha az gÃ¼rÃ¼ltÃ¼\n",
                "- **SSIM (Structural Similarity Index)**: 1'e yakÄ±n = yapÄ±sal benzerlik yÃ¼ksek\n",
                "\n",
                "---\n",
                "\n",
                "## Ã–nkoÅŸullar\n",
                "\n",
                "- `03_training.ipynb` ile eÄŸitilmiÅŸ model (.h5)\n",
                "- Validation dataset (NPY formatÄ±nda)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Google Colab iÃ§in\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Model Mimarisini YÃ¼kle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%run 01_model_architecture.ipynb"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. KaydedilmiÅŸ Modeli YÃ¼kle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import glob\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "# Model checkpoint dizini\n",
                "checkpoint_dir = \"/content/drive/MyDrive/TasarÄ±m Dersi/Projects/model_checkpoints\"\n",
                "\n",
                "# En son kaydedilen modeli bul\n",
                "list_of_files = glob.glob(os.path.join(checkpoint_dir, 'G_epoch_*.h5'))\n",
                "if not list_of_files:\n",
                "    raise ValueError(\"Model dosyasÄ± bulunamadÄ±!\")\n",
                "\n",
                "latest_file = max(list_of_files, key=os.path.getctime)\n",
                "print(f\"YÃ¼klenen Model: {os.path.basename(latest_file)}\")\n",
                "\n",
                "# Generator'Ä± yÃ¼kle\n",
                "generator = build_generator()\n",
                "generator.load_weights(latest_file)\n",
                "print(\"âœ… Model hazÄ±r.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Validation Verisini YÃ¼kle\n",
                "\n",
                "TÃ¼m veriyi RAM'e alÄ±yoruz (yaklaÅŸÄ±k 40-50 saniye sÃ¼rer)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Veri yolu\n",
                "dataset_path = \"/content/drive/MyDrive/TasarÄ±m Dersi/Projects/data/processed_data_npy\"\n",
                "\n",
                "# DosyalarÄ± al\n",
                "all_files_A = sorted(glob.glob(os.path.join(dataset_path, 'trainA') + '/*.npy'))\n",
                "all_files_B = sorted(glob.glob(os.path.join(dataset_path, 'trainB') + '/*.npy'))\n",
                "\n",
                "# Sadece eÅŸleÅŸenleri al\n",
                "filenames_A = {os.path.basename(f) for f in all_files_A}\n",
                "filenames_B = {os.path.basename(f) for f in all_files_B}\n",
                "common_filenames = sorted(list(filenames_A.intersection(filenames_B)))\n",
                "\n",
                "# %10 validation iÃ§in ayÄ±r\n",
                "from sklearn.model_selection import train_test_split\n",
                "filtered_files_A = [os.path.join(dataset_path, 'trainA', f) for f in common_filenames]\n",
                "filtered_files_B = [os.path.join(dataset_path, 'trainB', f) for f in common_filenames]\n",
                "\n",
                "_, val_files_A, _, val_files_B = train_test_split(\n",
                "    filtered_files_A, filtered_files_B, test_size=0.10, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Validation gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±: {len(val_files_A)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nVeriler RAM'e yÃ¼kleniyor...\")\n",
                "\n",
                "all_inputs = []\n",
                "all_targets = []\n",
                "\n",
                "for fA, fB in tqdm(zip(val_files_A, val_files_B), total=len(val_files_A)):\n",
                "    try:\n",
                "        imgA = np.load(fA)\n",
                "        imgB = np.load(fB)\n",
                "\n",
                "        # Boyut dÃ¼zeltme\n",
                "        if imgA.ndim == 2: imgA = np.expand_dims(imgA, axis=-1)\n",
                "        if imgB.ndim == 2: imgB = np.expand_dims(imgB, axis=-1)\n",
                "\n",
                "        all_inputs.append(imgA)\n",
                "        all_targets.append(imgB)\n",
                "    except:\n",
                "        continue\n",
                "\n",
                "X_val = np.array(all_inputs)\n",
                "Y_val = np.array(all_targets)\n",
                "print(f\"âœ… Veri HazÄ±r. Toplam GÃ¶rÃ¼ntÃ¼: {len(X_val)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. PSNR ve SSIM Hesapla\n",
                "\n",
                "RAM'i korumak iÃ§in 50'ÅŸerli batch'ler halinde hesaplÄ±yoruz."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nAnaliz BaÅŸlÄ±yor...\")\n",
                "\n",
                "psnr_scores = []\n",
                "ssim_scores = []\n",
                "\n",
                "batch_size = 50\n",
                "total_samples = len(X_val)\n",
                "\n",
                "for i in tqdm(range(0, total_samples, batch_size)):\n",
                "    batch_input = X_val[i : i + batch_size]\n",
                "    batch_target = Y_val[i : i + batch_size]\n",
                "\n",
                "    # Tahmin\n",
                "    batch_pred = generator(batch_input, training=False)\n",
                "\n",
                "    # PSNR/SSIM hesapla\n",
                "    # Veriler -1 ile 1 arasÄ±nda olduÄŸu iÃ§in max_val=2.0\n",
                "    batch_psnr = tf.image.psnr(batch_target, batch_pred, max_val=2.0).numpy()\n",
                "    batch_ssim = tf.image.ssim(batch_target, batch_pred, max_val=2.0).numpy()\n",
                "\n",
                "    psnr_scores.extend(batch_psnr)\n",
                "    ssim_scores.extend(batch_ssim)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. SonuÃ§lar"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "avg_psnr = np.mean(psnr_scores)\n",
                "std_psnr = np.std(psnr_scores)\n",
                "avg_ssim = np.mean(ssim_scores)\n",
                "std_ssim = np.std(ssim_scores)\n",
                "\n",
                "print(\"\\n\" + \"=\"*40)\n",
                "print(\"ðŸ“Š FÄ°NAL SONUÃ‡LAR\")\n",
                "print(\"=\"*40)\n",
                "print(f\"Ortalama PSNR: {avg_psnr:.4f} dB (Â±{std_psnr:.4f})\")\n",
                "print(f\"Ortalama SSIM: {avg_ssim:.4f} (Â±{std_ssim:.4f})\")\n",
                "print(\"=\"*40)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}