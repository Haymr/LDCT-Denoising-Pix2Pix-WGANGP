{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Mimarisi: U-Net Generator ve PatchGAN Discriminator\n",
                "\n",
                "Bu notebook, LDCT görüntü iyileştirme için kullandığımız hibrit Pix2Pix + WGAN-GP modelinin mimari tanımlarını içerir.\n",
                "\n",
                "**İçindekiler:**\n",
                "1. Encoder/Decoder blokları (downsample/upsample)\n",
                "2. U-Net Generator\n",
                "3. PatchGAN Discriminator\n",
                "4. WGAN-GP Hybrit Model sınıfı\n",
                "\n",
                "---\n",
                "\n",
                "## Neden Bu Mimari?\n",
                "\n",
                "Klasik Pix2Pix modelinde Binary Cross-Entropy loss kullanılırken, biz **Wasserstein loss + Gradient Penalty** kullanıyoruz. Bunun birkaç avantajı var:\n",
                "\n",
                "- Eğitim daha stabil (mode collapse riski düşük)\n",
                "- Discriminator'dan daha anlamlı gradyan akışı\n",
                "- L1 loss ile birlikte kullanınca hem yapısal hem de piksel-düzeyinde benzerlik sağlanıyor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers\n",
                "\n",
                "IMG_WIDTH = 256\n",
                "IMG_HEIGHT = 256\n",
                "CHANNELS = 1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Encoder ve Decoder Blokları\n",
                "\n",
                "U-Net mimarisinin temel yapı taşları. Encoder bloğu görüntüyü küçültür ve özellik çıkarır, decoder bloğu ise geri büyütür.\n",
                "\n",
                "- **downsample**: Conv2D → BatchNorm → LeakyReLU\n",
                "- **upsample**: Conv2DTranspose → BatchNorm → Dropout (opsiyonel) → ReLU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def downsample(filters, size, apply_batchnorm=True):\n",
                "    initializer = tf.random_normal_initializer(0., 0.02)\n",
                "    result = keras.Sequential()\n",
                "    result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n",
                "                             kernel_initializer=initializer, use_bias=False))\n",
                "    if apply_batchnorm:\n",
                "        result.add(layers.BatchNormalization())\n",
                "    result.add(layers.LeakyReLU())\n",
                "    return result\n",
                "\n",
                "def upsample(filters, size, apply_dropout=False):\n",
                "    initializer = tf.random_normal_initializer(0., 0.02)\n",
                "    result = keras.Sequential()\n",
                "    result.add(layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
                "                                      kernel_initializer=initializer, use_bias=False))\n",
                "    result.add(layers.BatchNormalization())\n",
                "    if apply_dropout:\n",
                "        result.add(layers.Dropout(0.5))\n",
                "    result.add(layers.ReLU())\n",
                "    return result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. U-Net Generator\n",
                "\n",
                "8 katmanlı encoder ve 7 katmanlı decoder. Skip connection'lar sayesinde düşük seviye özellikler korunuyor.\n",
                "\n",
                "```\n",
                "Input(256x256) → Encoder(8 blok) → Bottleneck(1x1) → Decoder(7 blok) → Output(256x256)\n",
                "                      ↓                                    ↑\n",
                "                      └──────── Skip Connections ──────────┘\n",
                "```\n",
                "\n",
                "Son katmanda `tanh` aktivasyonu kullanıyoruz çünkü çıktı [-1, 1] aralığında normalize edilmiş."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_generator():\n",
                "    inputs = layers.Input(shape=[IMG_WIDTH, IMG_HEIGHT, CHANNELS])\n",
                "\n",
                "    # Encoder\n",
                "    down_stack = [\n",
                "        downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
                "        downsample(128, 4), # (bs, 64, 64, 128)\n",
                "        downsample(256, 4), # (bs, 32, 32, 256)\n",
                "        downsample(512, 4), # (bs, 16, 16, 512)\n",
                "        downsample(512, 4), # (bs, 8, 8, 512)\n",
                "        downsample(512, 4), # (bs, 4, 4, 512)\n",
                "        downsample(512, 4), # (bs, 2, 2, 512)\n",
                "        downsample(512, 4), # (bs, 1, 1, 512)\n",
                "    ]\n",
                "\n",
                "    # Decoder\n",
                "    up_stack = [\n",
                "        upsample(512, 4, apply_dropout=True),\n",
                "        upsample(512, 4, apply_dropout=True),\n",
                "        upsample(512, 4, apply_dropout=True),\n",
                "        upsample(512, 4),\n",
                "        upsample(256, 4),\n",
                "        upsample(128, 4),\n",
                "        upsample(64, 4),\n",
                "    ]\n",
                "\n",
                "    initializer = tf.random_normal_initializer(0., 0.02)\n",
                "    last = layers.Conv2DTranspose(CHANNELS, 4, strides=2, padding='same',\n",
                "                                  kernel_initializer=initializer, activation='tanh')\n",
                "\n",
                "    x = inputs\n",
                "    skips = []\n",
                "    for down in down_stack:\n",
                "        x = down(x)\n",
                "        skips.append(x)\n",
                "\n",
                "    skips = reversed(skips[:-1])\n",
                "\n",
                "    for up, skip in zip(up_stack, skips):\n",
                "        x = up(x)\n",
                "        x = layers.Concatenate()([x, skip])\n",
                "\n",
                "    x = last(x)\n",
                "    return keras.Model(inputs=inputs, outputs=x)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. PatchGAN Discriminator\n",
                "\n",
                "70x70 patch üzerinde karar veren discriminator. Tüm görüntü yerine lokal bölgelere bakarak daha gerçekçi doku üretimini teşvik eder.\n",
                "\n",
                "**Not:** WGAN-GP kullandığımız için son katmanda sigmoid yok. Çıktı doğrudan \"Wasserstein distance\" hesabında kullanılıyor."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_discriminator():\n",
                "    #   Sigmoid fonksiyonu yerine WGAN-GP kullanılmıştır.\n",
                "    initializer = tf.random_normal_initializer(0., 0.02)\n",
                "\n",
                "    inp = layers.Input(shape=[IMG_WIDTH, IMG_HEIGHT, CHANNELS], name='input_image')\n",
                "    tar = layers.Input(shape=[IMG_WIDTH, IMG_HEIGHT, CHANNELS], name='target_image')\n",
                "\n",
                "    x = layers.Concatenate()([inp, tar]) # (bs, 256, 256, channels*2)\n",
                "\n",
                "    down1 = downsample(64, 4, False)(x)\n",
                "    down2 = downsample(128, 4)(down1)\n",
                "    down3 = downsample(256, 4)(down2)\n",
                "\n",
                "    # Zero Padding ve Conv\n",
                "    zero_pad1 = layers.ZeroPadding2D()(down3)\n",
                "    conv = layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1)\n",
                "    batchnorm1 = layers.BatchNormalization()(conv)\n",
                "    leaky_relu = layers.LeakyReLU()(batchnorm1)\n",
                "\n",
                "    zero_pad2 = layers.ZeroPadding2D()(leaky_relu)\n",
                "\n",
                "    last = layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)\n",
                "\n",
                "    return keras.Model(inputs=[inp, tar], outputs=last)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. WGAN-GP + Pix2Pix Hibrit Model\n",
                "\n",
                "Bu sınıf Keras Model API'sini kullanarak özel eğitim döngüsü tanımlar.\n",
                "\n",
                "**Kayıp Fonksiyonları:**\n",
                "- **Discriminator**: Wasserstein distance + Gradient Penalty\n",
                "- **Generator**: Wasserstein loss + L1 Reconstruction loss\n",
                "\n",
                "**Hiperparametreler:**\n",
                "- `lambda_gp=10`: Gradient Penalty ağırlığı (WGAN-GP makalesinden)\n",
                "- `lambda_l1=100`: L1 loss ağırlığı (orijinal Pix2Pix'ten)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WGAN_GP_Pix2Pix(keras.Model):\n",
                "    def __init__(self, generator, discriminator, lambda_gp=10.0, lambda_l1=100.0):\n",
                "        super(WGAN_GP_Pix2Pix, self).__init__()\n",
                "        self.generator = generator\n",
                "        self.discriminator = discriminator\n",
                "        self.lambda_gp = lambda_gp # Gradient Penalty ağırlığı\n",
                "        self.lambda_l1 = lambda_l1 # L1 (Pix2Pix) ağırlığı\n",
                "\n",
                "    def compile(self, d_optimizer, g_optimizer):\n",
                "        super(WGAN_GP_Pix2Pix, self).compile()\n",
                "        self.d_optimizer = d_optimizer\n",
                "        self.g_optimizer = g_optimizer\n",
                "        self.d_loss_fn = self.wasserstein_loss\n",
                "        self.g_loss_fn = self.wasserstein_loss\n",
                "        self.l1_loss_fn = tf.keras.losses.MeanAbsoluteError()\n",
                "\n",
                "    def wasserstein_loss(self, y_true, y_pred):\n",
                "        return tf.reduce_mean(y_true * y_pred)\n",
                "\n",
                "    def gradient_penalty(self, batch_size, real_images, fake_images, input_images):\n",
                "        \"\"\" GP Hesaplama: Real ve Fake arası interpolasyon \"\"\"\n",
                "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
                "        diff = fake_images - real_images\n",
                "        interpolated = real_images + alpha * diff\n",
                "\n",
                "        with tf.GradientTape() as gp_tape:\n",
                "            gp_tape.watch(interpolated)\n",
                "            # Discriminator'a hem input(LD) hem interpolasyon verilir\n",
                "            pred = self.discriminator([input_images, interpolated], training=True)\n",
                "\n",
                "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
                "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
                "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
                "        return gp\n",
                "\n",
                "    def call(self, inputs, training=False):\n",
                "        if isinstance(inputs, (list, tuple)):\n",
                "            inputs = inputs[0]\n",
                "        return self.generator(inputs, training=training)\n",
                "\n",
                "    def train_step(self, data):\n",
                "        # Data Loader'dan gelen veri: (input_image, target_image)\n",
                "        input_image, target_image = data\n",
                "        batch_size = tf.shape(input_image)[0]\n",
                "\n",
                "        # --- DISCRIMINATOR EĞİTİMİ ---\n",
                "        with tf.GradientTape() as tape:\n",
                "            fake_image = self.generator(input_image, training=True)\n",
                "\n",
                "            fake_pred = self.discriminator([input_image, fake_image], training=True)\n",
                "            real_pred = self.discriminator([input_image, target_image], training=True)\n",
                "\n",
                "            # Wasserstein Loss: D(fake) - D(real)\n",
                "\n",
                "            # Not: Real için -1, Fake için 1 gibi davranılır, formül minimize etmek üzerine kuruludur.\n",
                "\n",
                "            d_cost = tf.reduce_mean(fake_pred) - tf.reduce_mean(real_pred)\n",
                "\n",
                "            # Gradient Penalty\n",
                "            gp = self.gradient_penalty(batch_size, target_image, fake_image, input_image)\n",
                "\n",
                "            # Toplam D Loss\n",
                "            d_loss = d_cost + (gp * self.lambda_gp)\n",
                "\n",
                "        d_grad = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
                "        self.d_optimizer.apply_gradients(zip(d_grad, self.discriminator.trainable_variables))\n",
                "\n",
                "        # --- GENERATOR EĞİTİMİ ---\n",
                "        with tf.GradientTape() as tape:\n",
                "            fake_image = self.generator(input_image, training=True)\n",
                "            fake_pred = self.discriminator([input_image, fake_image], training=True)\n",
                "\n",
                "            # G Loss (Wasserstein Kısmı)\n",
                "            g_wgan_loss = -tf.reduce_mean(fake_pred)\n",
                "\n",
                "            # G Loss (L1 Kısmı): Orijinal Pix2Pix yapısı (Görüntü benzerliği)\n",
                "            g_l1_loss = self.l1_loss_fn(target_image, fake_image) * self.lambda_l1\n",
                "\n",
                "            g_loss = g_wgan_loss + g_l1_loss\n",
                "\n",
                "        g_grad = tape.gradient(g_loss, self.generator.trainable_variables)\n",
                "        self.g_optimizer.apply_gradients(zip(g_grad, self.generator.trainable_variables))\n",
                "\n",
                "        return {\"d_loss\": d_loss, \"g_loss\": g_loss, \"g_l1\": g_l1_loss}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Oluşturma\n",
                "\n",
                "Aşağıdaki hücreyi çalıştırarak modelleri oluşturabilirsiniz. Bu notebook'u diğer notebook'larda `%run` komutuyla çağırabilirsiniz."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "generator = build_generator()\n",
                "discriminator = build_discriminator()\n",
                "\n",
                "print(f\"Generator parametreleri: {generator.count_params():,}\")\n",
                "print(f\"Discriminator parametreleri: {discriminator.count_params():,}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}